{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_libraries.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNRwbedS9fnG8lJckvbuwlx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/minnano_ai/blob/master/section_7/ml_libraries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gpLdgYqPxp5",
        "colab_type": "text"
      },
      "source": [
        "# 機械学習ライブラリ\n",
        "機械学習ライブラリ、KerasとPyTorchのコードを紹介します。  \n",
        "今回はコードの詳しい解説は行いませんが、実装の大まかな流れを把握しましょう。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WguhKCRZdgV_",
        "colab_type": "text"
      },
      "source": [
        "## ● Kerasのコード\n",
        "以下のコードは、Kerasによるシンプルなニューラルネットワークの実装です。  \n",
        "Irisの各花を、SetosaとVersicolorに分類します。  \n",
        "以下のコードでは、`Sequential`でモデルを作り、層や活性化関数を追加しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uN-2AkcPCa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "iris_data = iris.data\n",
        "sl_data = iris_data[:100, 0] # SetosaとVersicolor、Sepal length\n",
        "sw_data = iris_data[:100, 1] # SetosaとVersicolor、Sepal width\n",
        "\n",
        "# 平均値を0に\n",
        "sl_ave = np.average(sl_data)  # 平均値\n",
        "sl_data -= sl_ave  # 平均値を引く\n",
        "sw_ave = np.average(sw_data)\n",
        "sw_data -= sw_ave\n",
        "\n",
        "# 入力をリストに格納\n",
        "input_data = []\n",
        "correct_data = []\n",
        "for i in range(100):\n",
        "    input_data.append([sl_data[i], sw_data[i]])\n",
        "    correct_data.append([iris.target[i]])\n",
        "\n",
        "# 訓練データとテストデータに分割\n",
        "input_data = np.array(input_data)  # NumPyの配列に変換\n",
        "correct_data = np.array(correct_data)\n",
        "x_train, x_test, t_train, t_test = train_test_split(input_data, correct_data)\n",
        "\n",
        "# ------ ここからKerasのコード ------\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(2, input_dim=2)) # 入力:2、中間層のニューロン数:2\n",
        "model.add(Activation(\"sigmoid\")) # シグモイド関数\n",
        "model.add(Dense(1)) # 出力層のニューロン数:1\n",
        "model.add(Activation(\"sigmoid\")) # シグモイド関数\n",
        "model.compile(optimizer=SGD(lr=0.3), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, t_train, epochs=32, batch_size=1)  # 訓練\n",
        "\n",
        "loss, accuracy = model.evaluate(x_test, t_test)\n",
        "print(\"正解率: \" + str(accuracy*100) + \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-gMuglhk1k9",
        "colab_type": "text"
      },
      "source": [
        "## ● PyTorchのコード\n",
        "以下のコードは、PyTorchよるシンプルなニューラルネットワークの実装です。  \n",
        "Irisの各花を、SetosaとVersicolorに分類します。  \n",
        "以下のコードでは、Kerasと同様に`Sequential`でモデルを作り、層や活性化関数を並べています。  \n",
        "PyTorchでは、入力や正解をTensor形式のデータに変換する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djZH-6V39iq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "iris_data = iris.data\n",
        "sl_data = iris_data[:100, 0] # SetosaとVersicolor、Sepal length\n",
        "sw_data = iris_data[:100, 1] # SetosaとVersicolor、Sepal width\n",
        "\n",
        "# 平均値を0に\n",
        "sl_ave = np.average(sl_data)  # 平均値\n",
        "sl_data -= sl_ave  # 平均値を引く\n",
        "sw_ave = np.average(sw_data)\n",
        "sw_data -= sw_ave\n",
        "\n",
        "# 入力をリストに格納\n",
        "input_data = []\n",
        "correct_data = []\n",
        "for i in range(100):\n",
        "    input_data.append([sl_data[i], sw_data[i]])\n",
        "    correct_data.append([iris.target[i]])\n",
        "\n",
        "# 訓練データとテストデータに分割\n",
        "input_data = np.array(input_data)  # NumPyの配列に変換\n",
        "correct_data = np.array(correct_data)\n",
        "x_train, x_test, t_train, t_test = train_test_split(input_data, correct_data)\n",
        "\n",
        "# ------ ここからPyTorchのコード ------\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "# Tensorに変換\n",
        "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "t_train = torch.tensor(t_train, dtype=torch.float32) \n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
        "t_test = torch.tensor(t_test, dtype=torch.float32) \n",
        "\n",
        "net = nn.Sequential(\n",
        "    nn.Linear(2, 2), # 入力:2、中間層のニューロン数:2\n",
        "    nn.Sigmoid(), # シグモイド関数\n",
        "    nn.Linear(2, 1), # 出力層のニューロン数:1\n",
        "    nn.Sigmoid() # シグモイド関数\n",
        ")\n",
        "\n",
        "loss_fnc = nn.MSELoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.3)\n",
        "\n",
        "# 1000エポック学習\n",
        "for i in range(1000):\n",
        "\n",
        "    # 勾配を0に\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 順伝播\n",
        "    y_train = net(x_train)\n",
        "    y_test = net(x_test)\n",
        "    \n",
        "    # 誤差を求める\n",
        "    loss_train = loss_fnc(y_train, t_train)\n",
        "    loss_test = loss_fnc(y_test, t_test)\n",
        "\n",
        "    # 逆伝播（勾配を求める）\n",
        "    loss_train.backward()\n",
        "    \n",
        "    # パラメータの更新\n",
        "    optimizer.step()\n",
        "\n",
        "    if i%100 == 0:\n",
        "        print(\"Epoch:\", i, \"Loss_Train:\", loss_train.item(), \"Loss_Test:\", loss_test.item())\n",
        "\n",
        "y_test = net(x_test)\n",
        "count = ((y_test.detach().numpy()>0.5) == (t_test.detach().numpy()==1.0)).sum().item()\n",
        "print(\"正解率: \" + str(count/len(y_test)*100) + \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}